# ü´Ä Heart Disease Prediction - ML Project

## üë• Equipe do Projeto

| Nome | GitHub |
|------|--------|
| [Evaldo Galdino] | [@evaldocunhaf](https://github.com/evaldocunhaf) |
| [Lizandra Vieira] | [@lizandravieira](https://github.com/lizandravieira) |
| [Kauan Novello] | [@kauan-novello](https://github.com/kauan-novello) |
| [Sofia Saraiva] | [@Sofia-Saraiva](https://github.com/Sofia-Saraiva) |
| [Pedro Henrique Silva Souza] | [@hsspedro](https://github.com/hsspedro) |



## üéì Informa√ß√µes Acad√™micas

- **Disciplina:** Aprendizado de M√°quina - 2025.2
- **Institui√ß√£o:** CESAR School
- **Projeto:** Predi√ß√£o de Doen√ßas Card√≠acas usando Machine Learning

## üìã Sobre o Projeto

Este projeto implementa um pipeline completo de Machine Learning para predi√ß√£o de doen√ßas card√≠acas, incluindo:

- **An√°lise Explorat√≥ria de Dados (EDA)** com visualiza√ß√µes interativas
- **Treinamento de m√∫ltiplos modelos** de classifica√ß√£o
- **Grid Search** para otimiza√ß√£o de hiperpar√¢metros
- **Cross-validation** para avalia√ß√£o robusta
- **Tracking de experimentos** com MLflow
- **API REST** para upload de dados
- **Dashboards** de visualiza√ß√£o com ThingsBoard
- **Ambientes de desenvolvimento** com JupyterLab e JupyterHub

## üèóÔ∏è Arquitetura do Projeto

```
ML-College-Project/
‚îú‚îÄ‚îÄ fastapi/              # API REST para upload de dados
‚îú‚îÄ‚îÄ mlflow/               # Tracking de experimentos ML
‚îú‚îÄ‚îÄ notebooks/            # Jupyter Notebooks com an√°lises
‚îú‚îÄ‚îÄ jupyterhub/          # Ambiente JupyterHub compartilhado
‚îú‚îÄ‚îÄ jupyterlab/          # Dados do JupyterLab
‚îú‚îÄ‚îÄ postgres-init/       # Scripts de inicializa√ß√£o do banco
‚îú‚îÄ‚îÄ reports/             # Relat√≥rios e documenta√ß√£o
‚îî‚îÄ‚îÄ docker-compose.yaml  # Orquestra√ß√£o dos servi√ßos
```

## üõ†Ô∏è Tecnologias Utilizadas

### Machine Learning & Data Science
- Python 3.11
- Scikit-learn
- Pandas, NumPy
- Matplotlib, Seaborn, Plotly
- MLflow

### Infraestrutura & DevOps
- Docker & Docker Compose
- FastAPI
- PostgreSQL 15
- ThingsBoard
- JupyterLab/JupyterHub
- AWS S3 (para armazenamento de artefatos)
- Snowflake (para armazenamento de dados)

## üì¶ Servi√ßos da Aplica√ß√£o

| Servi√ßo | Porta | Descri√ß√£o |
|---------|-------|-----------|
| **FastAPI** | 8060 | API para upload de dados CSV |
| **MLflow UI** | 5050 | Interface de tracking de experimentos |
| **JupyterLab** | 8888 | Ambiente de desenvolvimento individual |
| **JupyterHub** | 8001 | Ambiente de desenvolvimento compartilhado |
| **ThingsBoard** | 9090 | Dashboard de visualiza√ß√£o IoT |
| **Trendz Analytics** | 8889 | Analytics avan√ßado do ThingsBoard |
| **PostgreSQL** | 5433 | Banco de dados |

## üöÄ Instru√ß√µes de Instala√ß√£o e Execu√ß√£o

### üìã Pr√©-requisitos

- Docker Desktop instalado ([Download](https://www.docker.com/products/docker-desktop))
- Docker Compose (inclu√≠do no Docker Desktop)
- Git
- M√≠nimo de 8GB de RAM dispon√≠vel
- 10GB de espa√ßo em disco

### 1Ô∏è‚É£ Clone o Reposit√≥rio

```bash
git clone https://github.com/P-E-N-T-E-S/ML-College-Project.git
cd ML-College-Project
```

### 2Ô∏è‚É£ Configure as Vari√°veis de Ambiente

Crie um arquivo `.env` na pasta raiz do projeto com as seguintes vari√°veis:

```bash
# Snowflake Credentials
ACCOUNT_ID=sua_conta_snowflake
USERNAME=seu_usuario
PASSWORD=sua_senha
ROLE=seu_role
WAREHOUSE=seu_warehouse
DATABASE=seu_database
SCHEMA=seu_schema

# AWS S3 Credentials
AWS_ACCESS_KEY_ID=sua_access_key
AWS_SECRET_ACCESS_KEY=sua_secret_key
AWS_DEFAULT_REGION=us-east-2
BUCKET_NAME=seu_bucket
BUCKER_DIRECTORY=data/

# MLflow
METRICS_PATH=./metrics

# ThingsBoard
JWT_TOKEN_SIGNING_KEY=sua_chave_secreta_jwt
```

**Nota:** Para desenvolvimento local, voc√™ pode omitir as credenciais do Snowflake e AWS se n√£o for usar essas integra√ß√µes.

### 3Ô∏è‚É£ Crie o arquivo .env do MLflow

```bash
cp .env mlflow/.env
```

### 4Ô∏è‚É£ Levante a Infraestrutura

```bash
# Construir e iniciar todos os servi√ßos
docker compose up -d --build

# Ou iniciar servi√ßos espec√≠ficos
docker compose up -d fastapi mlflow jupyterlab jupyterhub
```

### 5Ô∏è‚É£ Verificar Status dos Containers

```bash
docker compose ps
```

Todos os servi√ßos devem estar com status "Up".

## üìä Acessando os Dashboards e Ferramentas

### üî¨ MLflow - Tracking de Experimentos

1. Acesse: http://localhost:5050
2. Visualize experimentos, m√©tricas e modelos treinados
3. Compare diferentes runs e hiperpar√¢metros

### üìì JupyterLab - Desenvolvimento Individual

1. Acesse: http://localhost:8888
2. Sem necessidade de token/senha
3. Notebooks dispon√≠veis em `/work`
4. Execute as an√°lises em `main.ipynb`

### üë• JupyterHub - Desenvolvimento Colaborativo

1. Acesse: http://localhost:8001
2. Login: qualquer usu√°rio (ex: `admin`)
3. Senha: deixe em branco ou digite qualquer coisa
4. Notebooks dispon√≠veis em `/workspace`

### üì° ThingsBoard - Dashboard IoT

1. Acesse: http://localhost:9090
2. Login padr√£o:
   - **Email:** tenant@thingsboard.org
   - **Senha:** tenant
3. Configure devices e dashboards para visualizar dados

### üöÄ FastAPI - API de Upload

```bash
# Testar endpoint
curl http://localhost:8060/hello

# Upload de arquivo CSV
curl -X POST "http://localhost:8060/upload" \
  -F "file=@/caminho/para/heart.csv"
```

Documenta√ß√£o interativa: http://localhost:8060/docs

## üìà Executando o Pipeline de ML

### Op√ß√£o 1: Via JupyterLab/JupyterHub

1. Acesse o JupyterLab (porta 8888) ou JupyterHub (porta 8001)
2. Abra o notebook `notebooks/main.ipynb`
3. Execute as c√©lulas sequencialmente:
   - Importa√ß√£o de dados do Snowflake
   - An√°lise explorat√≥ria com visualiza√ß√µes
   - Tratamento de outliers
   - Feature engineering
   - Treinamento de modelos (7 algoritmos)
   - Grid Search para otimiza√ß√£o
   - Cross-validation
   - Avalia√ß√£o de m√©tricas

### Op√ß√£o 2: Via Script Python

```bash
# Entrar no container do MLflow
docker exec -it mlflow bash

# Executar o pipeline
python main.py
```

## üß™ Modelos Implementados

O projeto treina e compara os seguintes modelos:

1. **Logistic Regression**
2. **Decision Tree**
3. **Random Forest**
4. **Gradient Boosting**
5. **Support Vector Machine (SVM)**
6. **Gaussian Naive Bayes**
7. **K-Nearest Neighbors (KNN)**

Cada modelo passa por:
- Grid Search para otimiza√ß√£o de hiperpar√¢metros
- Cross-validation (5 folds)
- Avalia√ß√£o com m√∫ltiplas m√©tricas:
  - Accuracy
  - Precision
  - Recall
  - F1-Score
  - Specificity
  - AUC-ROC

## üìä Visualiza√ß√µes Dispon√≠veis

O notebook inclui visualiza√ß√µes completas:

- üìä Distribui√ß√£o das vari√°veis target
- üìà Histogramas de vari√°veis num√©ricas
- üì¶ Boxplots por classe
- üî• Matriz de correla√ß√£o
- üéØ Top correla√ß√µes com target
- üìâ Scatter plots interativos
- üéª Violin plots por grupo
- üîÑ Pairplots multivariados
- üßÆ Matriz de confus√£o
- ‚≠ê Feature importance

## üõë Parando os Servi√ßos

```bash
# Parar todos os servi√ßos
docker compose down

# Parar e remover volumes (ATEN√á√ÉO: apaga dados persistidos)
docker compose down -v

# Parar apenas servi√ßos espec√≠ficos
docker compose stop mlflow jupyterlab
```

## üîÑ Reiniciando os Containers

```bash
# Script de reinicializa√ß√£o
./restart-containers.sh

# Ou manualmente
docker compose restart
```

## üêõ Troubleshooting

### Erro: "Port already in use"

```bash
# Verificar portas em uso
lsof -i :8888  # ou a porta espec√≠fica

# Parar containers conflitantes
docker compose down
```

### Erro: "Platform mismatch (linux/amd64 vs linux/arm64)"

J√° resolvido no docker-compose.yaml com `platform: linux/amd64`

### Erro: "Cannot connect to Snowflake"

Verifique as credenciais no arquivo `.env` e `mlflow/.env`

### Containers n√£o iniciam

```bash
# Ver logs detalhados
docker compose logs -f [nome_do_servico]

# Reconstruir imagens
docker compose up -d --build --force-recreate
```

## üìù Estrutura de Dados

O projeto utiliza o dataset **Heart Disease** com as seguintes features:

- **age:** Idade do paciente
- **sex:** Sexo (0=F, 1=M)
- **cp:** Tipo de dor no peito (0-3)
- **trestbps:** Press√£o arterial em repouso
- **chol:** Colesterol s√©rico
- **fbs:** Glicemia em jejum > 120 mg/dl
- **restecg:** Resultados eletrocardiogr√°ficos
- **thalach:** Frequ√™ncia card√≠aca m√°xima alcan√ßada
- **exang:** Angina induzida por exerc√≠cio
- **oldpeak:** Depress√£o ST induzida por exerc√≠cio
- **slope:** Inclina√ß√£o do segmento ST no exerc√≠cio
- **ca:** N√∫mero de vasos principais (0-3)
- **thal:** Talassemia (0=normal; 1=defeito fixo; 2=defeito revers√≠vel)
- **target:** Presen√ßa de doen√ßa card√≠aca (0=N√£o, 1=Sim)

## ü§ù Contribuindo

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa especificada no arquivo [LICENSE](LICENSE).

## üìû Contato

Para d√∫vidas ou sugest√µes, entre em contato com a equipe atrav√©s do GitHub.

---

**Desenvolvido com ‚ù§Ô∏è para CESAR School | Aprendizado de M√°quina 2025.2**
